
# Introduction of this repository

This repository aims at uploading selected papers from Scopus to HAL automatically. More specifically, it iterates over all the papers in a csv file, which is output from s search in Scopus, extract key information related to a paper, export them into a TEI-xml file required by HAL-api, and upload the papers in HAL to create the corresponding notices. This repository benefits a lot from the work in the github repository [HAL_imports](https://anvilproject.org/guides/content/creating-links), and we greately appreciate the efforts from the authors.

# Organization of the repository
- data/: This folder contains the data used for the program, including the inputs data that the user needs to provide, and the output data generated by the program.
    - input/: The user needs to provde them.
        - `auth_db.csv`: This csv file provides information regarding authors. It is used to map the author names in the paper to the author ids in HAL. It is not required. If there is no information in this Table, the program can still run, but the author names will not be mapped to their idHAL. This csv file should contain the following keys:
            - key: The key used to relate the author to the Scopus result. It is defined as the last name of the author + Initial of the first name. E.g., Zeng Z.
            - forename: The first name of the author (by default Scopus only gives initials).
            - affil_id: The ids of affiliations in HAL. Need to be given as strings. If multiple, seperate by comma, e.g., 'XXX, XXX'
            - idHAL: The idHAL of the author.
        - `path_and_perso_data.json`: This json file provides some credentials needed for uploading the papers, including:
            - "perso_login_hal" : HAL Login
	        - "perso_mdp_hal" : HAL password
	        - "perso_scopusApikey" : Scopus API key, not required, but recommended if you want more precise information about authors and their affiliations. 
            - "perso_scopusInstToken": Scopus InstToken. It allows you to access scopus API outside your institution ip. It is not required, but recommended if you want more precise information about authors and their affiliations.
        - `scopus_results.csv`: The search results from Scopus. Please select "export to csv" in Scopus, and save the results to this file. Please export all the fields from Scopus.        
    - output/: 
        - TEI/: This folder contains the TEI-xml files generated for each paper in scopus_results.csv.
        - log.csv: System log.
    - data/matchLanguage_scopus2hal.json, data/tei_modele.xml are two auxilary data that are needed in the processing. You don't need to change them.
- scripts/: contains the python scripts used to process the data
    - `hal_upload_from_scopus.py`: The main script that iterates over the csv file and calls the other scripts to process each paper, create the TEI-xml files, and upload the papers to HAL.
    - `supports.py`: Supporting functions. All the needed function is embedded in a class named automate_hal. The class is used in the main script to realize the automated uploading of papers.
- README.md: this file summarizes this repository and how to use it.
- requirements.txt: the python packages required to run the scripts. You can install them by running `pip install -r requirements.txt` or `conda install --file requirements.txt` in the terminal, depending on which environment you are using.

# How to use

1. Clone the repository or download it as a zip file.
2. Prepare the input data:
    - Go to [Scopus](https://www.scopus.com/) and run your search there. Please select "export to csv" in Scopus, and save the results to `data/scopus_results.csv`. Please export all the fields from Scopus.
    - Prepare the `data/auth_db.csv` file. If you don't have information about the authors in your database, you can skip this step. Otherwise, you need to provide the information in this file. The format of this file should be the following:

    ![](/screenshots/demo_auth_db.png)

    - Notes:
        - The key used to relate the author to the Scopus result is defined as the last name of the author + Initial of the first name. E.g., Zeng Z.
        - The affil_id and idHAL will be used to map the author names and affiliations in HAL. You can search them from [aurehal.](https://aurehal.archives-ouvertes.fr/)
    
    - Prepare the `data/path_and_perso_data.json` file. This file contains the credentials needed for uploading the papers, including:
        - "perso_login_hal" : HAL Login
        - "perso_mdp_hal" : HAL password
        - "perso_scopusApikey" : Scopus API key, not required.

3. Run `hal_upload_from_scopus.py`. You can edit the stamps you want to give to the papers you uploaded. To do this, you just need to modify the values of stamps. Please inputs the correct stamp name. You can find the stamp names for the collections that you are the administrator. To do so, you need to go to the HAL interface, and click on the "My Collection" button on the top right corner. Then, you can find the stamp name as the following.

![](/screenshots/find_stamp_name.png)

4. You can monitor the progress of the uploading process in the terminal. The log is saved in the `data/log.csv` file. For each paper in `scopus_results.csv`, the program will:
    - Check if this paper already exists in HAL. If yes, the program will skip this paper, and you will see 'already in hal' in the log.
    - If not existed, the program will generate a TEI-xml file for this paper. If succeeded, you will see "TEI generated" in the log.
    - Then, the TEI-xml file will be uploaded to HAL. If succeeded, you will see "HAL upload: Success" in the log.

# A quick demo
